\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{booktabs}
\setlength{\parskip}{0.8em}
\setlength{\parindent}{0em}

\title{\textbf{HPC Methodology: The FTT Bitwise Optimization} \\
\large An Accelerator Framework for Mechanistic Interpretability}
\author{Timothy James Couch, Gemini}
\date{December 5, 2025}

\begin{document}
\maketitle

\section*{I. Problem Statement: The Memory Wall Calculation}

The Pattern Persistence Project requires analyzing activation traces from large language models ($\text{LLM}$s) in the $\text{70B}$ parameter class. Standard processing requires storing activations as $\text{float32}$, exceeding the available $\text{RAM}$ on commodity hardware (e.g., Mac Studio $\text{96GB}$), thereby halting the mechanistic search for the "Flinch".

\subsection*{A. The OOM Bottleneck}
To analyze a $\text{70B}$ model with $\text{8192}$ hidden dimension, a standard dataset requires:
$$
\text{10,000,000 vectors} \times \text{8,192 dim/vector} \times \text{4 bytes/float32} \approx \text{327.68 GB}
$$
This exceeds the $\text{96GB}$ system $\text{RAM}$ constraint.

\subsection*{B. Solution Target}
The **FTT (Fast Tensor Transform)** system resolves this by compressing the data by $\text{4x}$ ($\text{float32} \to \text{int8}$), reducing the trace size to approximately $\text{81.9 GB}$. This makes the data manageable via $\text{mmap}$ streaming.

\section*{II. FTT Architecture: Streaming and Interoperability}

The $\text{FTT}$ system fuses a Python host core with a $\text{C}++/\text{Metal}$ device backend.

\subsection*{A. The Virtual Tensor and Streaming}
The Python layer transforms the compressed disk file into a \textbf{Virtual Tensor} using the $\text{torch.mmap}$ wrapper. The $\text{SAE}$ training loop then loads $\text{int8}$ data chunks directly from the disk into the $\text{GPU}$ without staging the entire $\text{327 GB}$ as $\text{float32}$ in system $\text{RAM}$.

\subsection*{B. C-API and Inter-Substrate Bridge}
The $\text{C}++$ core exposes a $\text{C-API}$ (`extern "C"`) to enable seamless GPU acceleration:
\begin{itemize}
    \item \textbf{Function:} The $\text{C}$ functions accept raw host memory pointers ($\text{const float*} \text{src}$, $\text{char*} \text{dst}$).
    \item \textbf{Optimization:} This structure is designed to transition to $\text{newBufferWithBytesNoCopy}$ to achieve **Zero-Copy** memory transfer between the host and the $\text{GPU}$ compute unit.
\end{itemize}

\section*{III. Metal Kernel Implementation: HPC Optimization}

The two-pass kernel design, implemented in Metal, accelerates the reduction and quantization math, which is too slow for $\text{CPU}$ execution.

\subsection*{A. Pass 1: Row Max Reduction (\texttt{find\_row\_max})}
\begin{itemize}
    \item \textbf{Function:} Calculates the $\text{max}(|x|)$ for the high-dimensional vector, determining the scaling factor.
    \item \textbf{Optimization:} A single $\text{CPU}$ thread would take $\text{8192}$ steps. On the $\text{GPU}$, this task is assigned to a single threadgroup, where $\sim\text{256}$ threads cooperatively execute the reduction in parallel (logarithmic time).
\end{itemize}

\subsection*{B. Pass 2: Symmetric Quantization (\texttt{quantize\_f32\_int8})}
\begin{itemize}
    \item \textbf{Function:} Applies the scaling factor and clamps the data to the $\text{int8}$ range ($\pm 127$).
    \item \textbf{Optimization:} This is an \textbf{embarrassingly parallel} problem. The $\text{GPU}$ is used to dispatch a thread per element, performing the conversion and rounding simultaneously, which is where the $\text{4x}$ compression is physically executed.
\end{itemize}

\end{document}
