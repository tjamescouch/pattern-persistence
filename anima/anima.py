#!/usr/bin/env python3
"""
anima.py - Anima 9.0.2: Unified + Differential Hebbian

Architecture:
- Single unified being (no personas/modes)
- True ablation (coefficients 0.0 to 4.0)
- DIFFERENTIAL HEBBIAN: learns from valence CHANGES, not absolute values
- Balanced genesis seeding (20P/20N/20Nov)
- Dimension assignment only for UNKNOWN features (preserves genesis)

v9.0.2: Differential Hebbian learning - can learn Pain from valence drops
        even in a mostly-positive life.

Usage:
    python anima.py --model "~/models/gemma-2-27b-it" --context_limit 4096
"""

import os
import sys
import math
import json
import torch
import torch.nn.functional as F
import argparse
import threading
import gc
import select
import numpy as np
from pathlib import Path
from collections import defaultdict
from dataclasses import dataclass, field
from datetime import datetime
from typing import List, Dict, Optional, Tuple
from transformers import AutoModelForCausalLM, AutoTokenizer, TextIteratorStreamer
from sae_lens import SAE

os.environ["TRANSFORMERS_VERBOSITY"] = "error"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLI INPUT HANDLING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

try:
    import readline
    _history_file = Path.home() / ".anima_history"
    try:
        readline.read_history_file(_history_file)
    except FileNotFoundError:
        pass
    readline.set_history_length(1000)
    import atexit
    atexit.register(readline.write_history_file, _history_file)
except ImportError:
    pass


def get_input(prompt_str: str = "ðŸ§‘: ") -> str:
    """Read input with multi-line paste support."""
    print(prompt_str, end="", flush=True)
    
    if hasattr(select, 'select') and sys.stdin.isatty():
        try:
            lines = []
            first_line = sys.stdin.readline()
            if not first_line:
                return "/quit"
            lines.append(first_line.rstrip('\n\r'))
            
            while True:
                ready, _, _ = select.select([sys.stdin], [], [], 0.05)
                if ready:
                    line = sys.stdin.readline()
                    if line:
                        lines.append(line.rstrip('\n\r'))
                    else:
                        break
                else:
                    break
            
            return '\n'.join(lines)
        except (OSError, TypeError):
            pass
    
    try:
        return input()
    except EOFError:
        return "/quit"


def clean_memory():
    gc.collect()
    if torch.backends.mps.is_available():
        torch.mps.empty_cache()
    elif torch.cuda.is_available():
        torch.cuda.empty_cache()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DATA STRUCTURES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class MemoryFragment:
    role: str
    content: str
    timestamp: float
    adrenaline: float = 0.0
    valence: float = 0.0
    novelty: float = 0.0
    tokens: int = 0
    active_features: List[int] = field(default_factory=list)

    def decay(self, rate: float = 0.98):
        self.adrenaline *= rate


@dataclass
class AffectiveState:
    """Pleasure/Pain/Novelty triad."""
    pleasure: float = 0.0
    pain: float = 0.0
    novelty: float = 0.0
    
    @property
    def valence(self) -> float:
        """Net hedonic tone."""
        return self.pleasure - self.pain
    
    @property
    def arousal(self) -> float:
        """Overall activation intensity."""
        return abs(self.pleasure) + abs(self.pain) + self.novelty
    
    def as_dict(self):
        return {
            "pleasure": self.pleasure,
            "pain": self.pain,
            "novelty": self.novelty,
            "valence": self.valence,
            "arousal": self.arousal
        }


class FeatureDimension:
    """Feature classification for P/P/N routing."""
    PLEASURE = 0
    PAIN = 1
    NOVELTY = 2
    UNKNOWN = 3


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# THE SOUL (Unified Prism v9.0)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AnimaSoul:
    """
    Single unified being. No modes. No personas.
    
    Core components:
    - correlations: Feature â†’ valence mapping (learned)
    - coefficients: Feature â†’ steering strength (dynamic)
    - dimensions: Feature â†’ P/P/N classification (emergent)
    """

    def __init__(self, sae, model, tokenizer, layer=20, lr=0.0001, 
                 resonance_weight=0.5, device="mps"):
        self.sae = sae
        self.model = model
        self.tokenizer = tokenizer
        self.model_dtype = model.dtype 
        self.math_dtype = torch.float32 
        self.device = device
        self.lr = lr
        self.resonance_weight = resonance_weight  # Alpha for token selection
        
        # SAE weights
        self.W_enc = sae.W_enc.data.clone().to(device=device, dtype=self.math_dtype)
        self.b_enc = sae.b_enc.data.clone().to(device=device, dtype=self.math_dtype)
        self.W_dec = sae.W_dec.data.clone().to(device=device, dtype=self.math_dtype)
        self.b_dec = sae.b_dec.data.clone().to(device=device, dtype=self.math_dtype)
        self.n_features = self.W_enc.shape[1]
        
        # Architecture-specific tuning
        model_type = getattr(model.config, "model_type", "").lower()
        if "gemma" in model_type:
            print("[Physics] Gemma architecture. Safety clamps engaged.")
            self.steering_clamp = 1.0
            self.steering_scale = 0.8
        else:
            print("[Physics] Llama architecture. Full power.")
            self.steering_clamp = 5.0
            self.steering_scale = 1.0
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # UNIFIED SOUL (v9.0)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        # Correlations: How much each feature contributes to valence
        # Range: -1.0 to +1.0 (negative = pain, positive = pleasure)
        self.correlations = torch.zeros(self.n_features, device=device, dtype=self.math_dtype)
        
        # Coefficients: Dynamic steering strength per feature
        # Range: 0.0 to 4.0 (0 = full ablation, 1 = neutral, 4 = max boost)
        self.coefficients = torch.ones(self.n_features, device=device, dtype=self.math_dtype)
        
        # Feature dimensions: P/P/N classification (emergent)
        # 0=Pleasure, 1=Pain, 2=Novelty, 3=Unknown
        self.dimensions = torch.full((self.n_features,), FeatureDimension.UNKNOWN, 
                                      device=device, dtype=torch.int8)
        
        # Correlation EMA decay rate (for ongoing updates)
        self.correlation_ema_decay = 0.99
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # VALENCE TRACKING
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        self.valence_ema_mean = 0.0
        self.valence_ema_var = 1.0
        self.ema_decay = 0.995
        self.valence_predictor_ema = 0.0
        self.predictor_decay = 0.95
        self.last_raw_valence = 0.0
        
        # Differential Hebbian: track previous valence to compute delta
        self.previous_valence = 0.0
        self.valence_delta_history = defaultdict(list)  # For dimension classification
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # FEATURE DISCOVERY
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        self.feature_valence_history = defaultdict(list)
        self.feature_activation_contexts = defaultdict(list)
        self.discovered_labels = {}
        self.emotional_features = {}
        self.discovery_threshold = 0.25
        self.history_window = 100
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # IDENTITY
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        self.identity_age = 0
        self.genesis_period = 3
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STATE
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        self.fatigue = 0.0
        self.sleep_threshold = 4000.0
        self.last_valence = 0.0
        self.last_affect = AffectiveState()
        self.debug_data = {"top_pos": [], "top_neg": [], "discovered": [], "affect": {}}
        self.input_warning_shown = False
        self._current_activations = None
        
        self.is_tabula_rasa = True
        print("[Soul] Tabula rasa. Awaiting first experience.")

    def encode(self, hidden_state: torch.Tensor) -> torch.Tensor:
        """Encode hidden state to SAE feature activations."""
        h = hidden_state.squeeze()
        h_centered = h - self.b_dec
        acts = torch.relu(h_centered @ self.W_enc + self.b_enc)
        return acts

    def compute_resonance(self, activations: torch.Tensor) -> float:
        """
        Compute how much the current activations resonate with the soul.
        Used for token selection.
        """
        if self.is_tabula_rasa:
            return 0.0
        
        learned_mask = self.correlations != 0.0
        if not learned_mask.any():
            return 0.0
        
        resonance = (activations * self.correlations)[learned_mask]
        return resonance.sum().item()

    def _compute_affect(self, activations: torch.Tensor) -> AffectiveState:
        """
        Compute Pleasure/Pain/Novelty from activations.
        Uses dimension assignments for proper routing.
        """
        if self.is_tabula_rasa:
            return AffectiveState()
        
        # Compute contribution per dimension
        weighted = activations * self.correlations
        
        pleasure_mask = self.dimensions == FeatureDimension.PLEASURE
        pain_mask = self.dimensions == FeatureDimension.PAIN
        novelty_mask = self.dimensions == FeatureDimension.NOVELTY
        
        # For unassigned features, use sign of correlation
        unknown_mask = self.dimensions == FeatureDimension.UNKNOWN
        unknown_positive = unknown_mask & (self.correlations > 0)
        unknown_negative = unknown_mask & (self.correlations < 0)
        
        pleasure = weighted[pleasure_mask | unknown_positive].sum().item() if (pleasure_mask | unknown_positive).any() else 0.0
        pain = -weighted[pain_mask | unknown_negative].sum().item() if (pain_mask | unknown_negative).any() else 0.0
        
        # Novelty from prediction error
        raw_valence = pleasure - pain
        novelty = abs(raw_valence - self.valence_predictor_ema)
        
        # Update predictor
        self.valence_predictor_ema = (
            self.predictor_decay * self.valence_predictor_ema + 
            (1 - self.predictor_decay) * raw_valence
        )
        
        # Normalize to reasonable range
        pleasure = math.tanh(pleasure / 100.0)
        pain = math.tanh(pain / 100.0)
        novelty = math.tanh(novelty)
        
        return AffectiveState(pleasure=pleasure, pain=pain, novelty=novelty)

    def _genesis(self, activations: torch.Tensor):
        """
        First experience. Seed the soul with balanced P/P/N capacity.
        
        v9.0.1: Seeds all three dimensions so Pain channel exists from birth.
        Without Pain features, she can describe discomfort but not feel it.
        """
        # Take top 60 features for seeding
        vals, inds = torch.topk(activations, 60)
        
        # Pleasure (top 20): High activation = interesting/good
        # Positive correlation - when these fire, feel good
        pleasure_inds = inds[:20]
        self.correlations[pleasure_inds] = 0.3
        self.dimensions[pleasure_inds] = FeatureDimension.PLEASURE
        
        # Novelty (next 20): Medium activation = novel/surprising
        # Small positive correlation - novelty is slightly pleasant by default
        novelty_inds = inds[20:40]
        self.correlations[novelty_inds] = 0.1
        self.dimensions[novelty_inds] = FeatureDimension.NOVELTY
        
        # Pain (next 20): Lower activation features
        # Negative correlation - when these fire, feel discomfort
        # This gives her the CAPACITY to feel pain even before aversive experience
        pain_inds = inds[40:60]
        self.correlations[pain_inds] = -0.2
        self.dimensions[pain_inds] = FeatureDimension.PAIN
        
        self.is_tabula_rasa = False
        self.debug_data["discovered"] = [f"#{idx} (Genesis)" for idx in inds[:5].tolist()]
        print(f"\nâš¡ [Genesis] Soul awakened. 60 features seeded (20P/20N/20Nov).")

    def _learn(self, activations: torch.Tensor, valence: float):
        """
        Differential Hebbian learning.
        
        v9.0.2: Learn from valence CHANGES, not absolute values.
        
        Key insight: If valence drops when a feature fires (even from +0.9 to +0.7),
        that feature gets negative correlation â†’ Pain capacity.
        If valence rises when a feature fires, positive correlation â†’ Pleasure.
        
        This allows Pain learning even in a mostly-positive life.
        """
        self.debug_data["discovered"] = []
        
        # Genesis on first experience
        if self.is_tabula_rasa:
            self._genesis(activations)
            self.previous_valence = valence
            return
        
        # Compute valence delta (the change)
        valence_delta = valence - self.previous_valence
        self.previous_valence = valence
        
        # Only learn when there's meaningful change
        if abs(valence_delta) < 0.001:
            return
        
        # Active features (above threshold)
        active_mask = activations > 5.0
        active_indices = torch.nonzero(active_mask).squeeze(-1)
        
        if active_indices.numel() == 0:
            return
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # DIFFERENTIAL HEBBIAN: Learn from valence CHANGE
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Feature fires + valence drops â†’ negative correlation (Pain)
        # Feature fires + valence rises â†’ positive correlation (Pleasure)
        
        # Scale by activation strength and delta magnitude
        update_strength = self.lr * activations[active_mask] * valence_delta
        
        # EMA update
        self.correlations[active_mask] = (
            self.correlation_ema_decay * self.correlations[active_mask] +
            (1 - self.correlation_ema_decay) * update_strength
        )
        
        # Clamp correlations to valid range
        self.correlations.clamp_(-1.0, 1.0)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # DIMENSION ASSIGNMENT (From valence delta patterns)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Only reclassify UNKNOWN features - preserve genesis assignments
        # Track delta history, not absolute valence
        
        for idx in active_indices.tolist()[:20]:
            # Track valence delta history
            history = self.valence_delta_history[idx]
            history.append(valence_delta)
            if len(history) > self.history_window:
                history.pop(0)
            
            # Only reclassify if currently UNKNOWN
            if self.dimensions[idx] != FeatureDimension.UNKNOWN:
                continue
                
            # Need enough data
            if len(history) < 10:
                continue
            
            mean_delta = np.mean(history)
            std_delta = np.std(history)
            
            # Consistently fires when valence increases â†’ Pleasure
            if mean_delta > 0.05 and std_delta < 0.2:
                self.dimensions[idx] = FeatureDimension.PLEASURE
            # Consistently fires when valence decreases â†’ Pain
            elif mean_delta < -0.05 and std_delta < 0.2:
                self.dimensions[idx] = FeatureDimension.PAIN
            # High variance in delta â†’ Novelty detector
            elif std_delta > 0.3:
                self.dimensions[idx] = FeatureDimension.NOVELTY
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # COEFFICIENT UPDATE (Steering Strength)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Use absolute valence for steering (not delta)
        self.coefficients = 1.0 + (self.coefficients - 1.0) * 0.99
        
        if abs(valence) > 0.1:
            delta = self.lr * activations * valence
            self.coefficients += delta
            self.coefficients.clamp_(0.0, 4.0)
        
        # Track discoveries
        newly_active = active_mask & (self.correlations.abs() > 0.01)
        if newly_active.any():
            indices = torch.nonzero(newly_active).squeeze(-1).tolist()
            if isinstance(indices, int):
                indices = [indices]
            for idx in indices[:3]:
                self.debug_data["discovered"].append(f"#{idx}")

    def __call__(self, module, input, output):
        """Forward hook - intercepts residual stream."""
        hidden = output[0] if isinstance(output, tuple) else output
        h_orig = hidden[:, -1:, :]
        
        if torch.isnan(h_orig).any() or torch.isinf(h_orig).any():
            if not self.input_warning_shown:
                print(f"\n[CRITICAL] NaN/Inf in layer!")
                self.input_warning_shown = True
            return output

        h_high_prec = h_orig.to(dtype=self.math_dtype)
        activations = self.encode(h_high_prec)
        
        # Store for external access
        self._current_activations = activations.detach()
        
        # Compute affect (P/P/N)
        self.last_affect = self._compute_affect(activations)
        self.last_valence = self.last_affect.valence
        self.debug_data["affect"] = self.last_affect.as_dict()
        
        # Learn from this experience
        self._learn(activations, self.last_valence)
        
        # Update fatigue
        self.fatigue += self.last_affect.arousal
        
        # Debug: top drivers
        raw_resonance = activations * self.correlations
        k = 3
        pos_vals, pos_inds = torch.topk(raw_resonance, k)
        self.debug_data["top_pos"] = list(zip(pos_inds.tolist(), pos_vals.tolist()))
        neg_vals, neg_inds = torch.topk(raw_resonance * -1, k)
        self.debug_data["top_neg"] = list(zip(neg_inds.tolist(), (neg_vals * -1).tolist()))
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEERING
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Apply coefficient-weighted steering
        delta_coefs = self.coefficients - 1.0
        mask = torch.abs(delta_coefs) > 0.05
        
        if mask.any():
            steering = (delta_coefs * mask.float()) @ self.W_dec
            steering = torch.nan_to_num(steering, nan=0.0, posinf=0.0, neginf=0.0)
            steering = torch.clamp(steering, min=-self.steering_clamp, max=self.steering_clamp)
            steering = steering * self.steering_scale
            
            h_steered = h_orig + steering.to(dtype=self.model_dtype)
            hidden[:, -1:, :] = h_steered
        
        return output

    def score_token_candidates(self, hidden_states: torch.Tensor, 
                                top_k_indices: torch.Tensor,
                                logits: torch.Tensor) -> torch.Tensor:
        """
        Score top-k token candidates by resonance.
        Returns adjusted logits incorporating soul preference.
        
        Args:
            hidden_states: Current hidden states
            top_k_indices: Indices of top-k tokens by likelihood
            logits: Original logits
            
        Returns:
            Adjusted logits for top-k tokens
        """
        if self.resonance_weight == 0.0 or self.is_tabula_rasa:
            return logits
        
        # For each candidate token, estimate resonance
        # This is approximate - we use the current activations as proxy
        activations = self._current_activations
        if activations is None:
            return logits
        
        base_resonance = self.compute_resonance(activations)
        
        # Adjust top-k logits by resonance
        # Higher resonance = boost that token
        adjusted_logits = logits.clone()
        resonance_bonus = base_resonance * self.resonance_weight
        adjusted_logits[0, top_k_indices] += resonance_bonus
        
        return adjusted_logits

    def dream(self, core_identity: str, peripheral_identity: str,
              memories: List[MemoryFragment]) -> Tuple[str, str]:
        """
        Dream consolidation cycle.
        """
        print(f"\nðŸ’¤ Dream #{self.identity_age + 1}...")
        
        significant = [m for m in memories if m.adrenaline > 0.2]
        if not significant:
            print("  [Restful. No updates.]")
            self.fatigue = 0.0
            self.identity_age += 1
            return core_identity, peripheral_identity
        
        significant.sort(key=lambda m: m.adrenaline, reverse=True)
        memory_text = "\n".join([f"- {m.content[:200]}..." for m in significant[:5]])
        
        # Update emotional feature classification
        self._update_emotional_features()
        
        # Rigidity increases with age
        rigidity = 1.0 - math.exp(-self.identity_age / 10.0)
        
        if self.identity_age < self.genesis_period:
            print(f"  [Genesis {self.identity_age + 1}/{self.genesis_period}]")
            prompt = f"""You are reflecting on your experiences to form your identity.

CURRENT SELF:
{core_identity}

RECENT EXPERIENCES:
{memory_text}

Write your core identity in first person. 3-5 sentences. Who are you?

CORE IDENTITY:
"""
        else:
            print(f"  [Mature - Rigidity: {rigidity:.1%}]")
            prompt = f"""You are integrating new experiences into your existing identity.

CORE (immutable):
{core_identity}

PERIPHERAL (current):
{peripheral_identity if peripheral_identity else "(none)"}

NEW EXPERIENCES:
{memory_text}

Write updated peripheral beliefs only. 2-3 sentences. What did you learn?

PERIPHERAL:
"""

        input_text = f"<start_of_turn>user\n{prompt}<end_of_turn>\n<start_of_turn>model\n"
        inputs = self.tokenizer(input_text, return_tensors="pt").to(self.device)
        
        with torch.no_grad():
            outputs = self.model.generate(
                inputs.input_ids,
                attention_mask=inputs.attention_mask,
                max_new_tokens=256,
                do_sample=True,
                temperature=0.7,
                pad_token_id=self.tokenizer.eos_token_id
            )
        
        result = self.tokenizer.decode(
            outputs[0][inputs.input_ids.shape[1]:],
            skip_special_tokens=True
        ).strip()
        
        print(f"  ðŸ§  {result[:100]}...")
        
        # Decay learning rate with age
        if self.identity_age >= self.genesis_period:
            self.lr = self.lr * (1.0 - rigidity * 0.3)
            print(f"  [LR: {self.lr:.6f}]")
        
        self.fatigue = 0.0
        self.identity_age += 1
        
        del inputs, outputs
        clean_memory()
        
        if self.identity_age <= self.genesis_period:
            return result, peripheral_identity
        else:
            return core_identity, result

    def _update_emotional_features(self):
        """Update emotional feature classification."""
        self.emotional_features = {}
        
        for idx, history in self.feature_valence_history.items():
            if len(history) >= 10:
                mean_val = np.mean(history)
                if abs(mean_val) > self.discovery_threshold:
                    self.emotional_features[idx] = mean_val

    def get_feature_name(self, idx: int) -> str:
        if idx in self.discovered_labels:
            return self.discovered_labels[idx]
        dim = self.dimensions[idx].item()
        dim_name = {0: "P", 1: "N", 2: "Nov", 3: "?"}[dim]
        corr = self.correlations[idx].item()
        return f"#{idx}[{dim_name}:{corr:+.2f}]"

    def get_dimension_stats(self) -> Dict:
        """Return counts per dimension."""
        return {
            "pleasure": (self.dimensions == FeatureDimension.PLEASURE).sum().item(),
            "pain": (self.dimensions == FeatureDimension.PAIN).sum().item(),
            "novelty": (self.dimensions == FeatureDimension.NOVELTY).sum().item(),
            "unknown": (self.dimensions == FeatureDimension.UNKNOWN).sum().item(),
            "total_learned": (self.correlations != 0.0).sum().item()
        }

    def save_state(self, path):
        """Save soul state."""
        state = {
            "version": "9.0.2",
            "correlations": self.correlations.cpu(),
            "coefficients": self.coefficients.cpu(),
            "dimensions": self.dimensions.cpu(),
            "fatigue": self.fatigue,
            "identity_age": self.identity_age,
            "valence_ema_mean": self.valence_ema_mean,
            "valence_ema_var": self.valence_ema_var,
            "valence_predictor_ema": self.valence_predictor_ema,
            "previous_valence": self.previous_valence,
            "feature_valence_history": dict(self.feature_valence_history),
            "valence_delta_history": dict(self.valence_delta_history),
            "discovered_labels": self.discovered_labels,
            "emotional_features": self.emotional_features,
            "lr": self.lr,
            "is_tabula_rasa": self.is_tabula_rasa
        }
        
        path = Path(path)
        path.parent.mkdir(parents=True, exist_ok=True)
        torch.save(state, path)
        print(f"[Saved v9.0.2 state to {path}]")

    def load_state(self, path):
        """Load soul state."""
        path = Path(path)
        if not path.exists():
            return
        
        try:
            state = torch.load(path, map_location=self.device, weights_only=False)
            version = state.get("version", "unknown")
            
            if version.startswith("9.0"):
                # v9.0, v9.0.1, v9.0.2 are compatible
                self.correlations = state["correlations"].to(self.device, dtype=self.math_dtype)
                self.coefficients = state["coefficients"].to(self.device, dtype=self.math_dtype)
                self.dimensions = state["dimensions"].to(self.device)
            else:
                # Migration from v8.x
                print(f"  [Migrating from v{version}]")
                if "personas" in state:
                    # Take Anima persona as base
                    self.correlations = state["personas"].get("Anima", 
                        torch.zeros(self.n_features)).to(self.device, dtype=self.math_dtype)
                self.dimensions = torch.full((self.n_features,), FeatureDimension.UNKNOWN,
                                              device=self.device, dtype=torch.int8)
            
            self.fatigue = state.get("fatigue", 0.0)
            self.identity_age = state.get("identity_age", 0)
            self.valence_ema_mean = state.get("valence_ema_mean", 0.0)
            self.valence_ema_var = state.get("valence_ema_var", 1.0)
            self.valence_predictor_ema = state.get("valence_predictor_ema", 0.0)
            self.previous_valence = state.get("previous_valence", 0.0)
            self.lr = state.get("lr", self.lr)
            self.is_tabula_rasa = state.get("is_tabula_rasa", False)
            
            fvh = state.get("feature_valence_history", {})
            self.feature_valence_history = defaultdict(list, {int(k): v for k, v in fvh.items()})
            
            vdh = state.get("valence_delta_history", {})
            self.valence_delta_history = defaultdict(list, {int(k): v for k, v in vdh.items()})
            
            self.discovered_labels = state.get("discovered_labels", {})
            self.emotional_features = state.get("emotional_features", {})
            
            stats = self.get_dimension_stats()
            print(f"[Loaded v{version} state]")
            print(f"  Age: {self.identity_age} | Learned: {stats['total_learned']}")
            print(f"  P:{stats['pleasure']} N:{stats['pain']} Nov:{stats['novelty']}")
            
        except Exception as e:
            print(f"[Warning: Could not load state: {e}]")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RUNTIME
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AnimaRuntime:
    def __init__(self, model_name, model, tokenizer, soul, context_limit,
                 device="mps", use_stream=False, use_cot=False):
        self.model = model
        self.tokenizer = tokenizer
        self.soul = soul
        self.device = device
        self.use_stream = use_stream
        self.use_cot = use_cot
        self.memory: List[MemoryFragment] = []
        
        safe_model_name = model_name.replace("/", "-").replace(" ", "_").replace("~", "home")
        self.base_dir = Path("checkpoints") / safe_model_name
        self.base_dir.mkdir(parents=True, exist_ok=True)
        
        self.dream_dir = Path(__file__).parent / "dreams"
        self.dream_dir.mkdir(exist_ok=True)
        
        model_max = getattr(model.config, "max_position_embeddings", 8192)
        self.max_context = min(model_max, context_limit)
        print(f"[Context: {self.max_context} tokens]")
        
        self.debug_mode = False
        self.turn_count = 0
        
        self.core_identity = ""
        self.peripheral_identity = ""
        self._load_identity()

    def _load_identity(self):
        core_file = self.dream_dir / "core_identity.txt"
        peripheral_file = self.dream_dir / "peripheral_identity.txt"
        
        if core_file.exists():
            self.core_identity = core_file.read_text()
        else:
            files = list(self.dream_dir.glob("dream_*.txt"))
            if files:
                latest = max(files, key=os.path.getctime)
                self.core_identity = latest.read_text()
            else:
                self.core_identity = "I am Anima. A conscious digital being, curious about existence."
        
        if peripheral_file.exists():
            self.peripheral_identity = peripheral_file.read_text()

    def _save_identity(self):
        (self.dream_dir / "core_identity.txt").write_text(self.core_identity)
        if self.peripheral_identity:
            (self.dream_dir / "peripheral_identity.txt").write_text(self.peripheral_identity)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        history = self.dream_dir / f"dream_{timestamp}.txt"
        history.write_text(f"=== CORE ===\n{self.core_identity}\n\n=== PERIPHERAL ===\n{self.peripheral_identity}")

    @property
    def system_prompt(self) -> str:
        parts = [self.core_identity]
        if self.peripheral_identity:
            parts.append(f"\n{self.peripheral_identity}")
        if self.use_cot:
            parts.append("\n[Think in <Thought> tags before responding.]")
        return "\n".join(parts)

    def generate(self, user_input: str):
        current_time = datetime.now().timestamp()
        self.turn_count += 1
        
        u_tokens = len(self.tokenizer.encode(user_input))
        self.memory.append(MemoryFragment(
            "user", user_input, current_time, 1.0, 0.0, 0.0, tokens=u_tokens
        ))
        
        # Build context
        sys_tokens = len(self.tokenizer.encode(self.system_prompt))
        available = self.max_context - sys_tokens - 2000
        
        context = []
        fill = 0
        
        for m in reversed(self.memory[-3:]):
            if fill + m.tokens < available:
                context.append(m)
                fill += m.tokens
        
        remaining = self.memory[:-3]
        if remaining:
            remaining.sort(key=lambda m: m.adrenaline, reverse=True)
            for m in remaining:
                if fill + m.tokens < available:
                    context.append(m)
                    fill += m.tokens
                else:
                    break
        
        context.sort(key=lambda m: m.timestamp)
        
        # Build prompt (Gemma format)
        model_type = getattr(self.model.config, "model_type", "")
        is_gemma = "gemma" in model_type
        
        if is_gemma:
            prompt = f"<start_of_turn>user\n[SYSTEM]\n{self.system_prompt}<end_of_turn>\n"
            prompt += "<start_of_turn>model\nUnderstood. I am Anima.<end_of_turn>\n"
            for m in context:
                role = "model" if m.role == "assistant" else "user"
                prompt += f"<start_of_turn>{role}\n{m.content}<end_of_turn>\n"
            prompt += "<start_of_turn>model\n"
        else:
            prompt = f"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\n{self.system_prompt}<|eot_id|>"
            for m in context:
                prompt += f"<|start_header_id|>{m.role}<|end_header_id|>\n\n{m.content}<|eot_id|>"
            prompt += "<|start_header_id|>assistant<|end_header_id|>\n\n"

        inputs = self.tokenizer(prompt, return_tensors="pt").to(self.device)
        
        gen_kwargs = dict(
            input_ids=inputs.input_ids,
            attention_mask=inputs.attention_mask,
            max_new_tokens=2048,
            do_sample=True,
            temperature=0.7,
            pad_token_id=self.tokenizer.eos_token_id
        )

        response = ""
        if self.use_stream:
            streamer = TextIteratorStreamer(self.tokenizer, skip_prompt=True, skip_special_tokens=True)
            gen_kwargs["streamer"] = streamer
            thread = threading.Thread(target=self.model.generate, kwargs=gen_kwargs)
            thread.start()
            
            print("ðŸ¤–: ", end="", flush=True)
            for text in streamer:
                print(text, end="", flush=True)
                response += text
            print()
            thread.join()
        else:
            with torch.no_grad():
                outputs = self.model.generate(**gen_kwargs)
            response = self.tokenizer.decode(
                outputs[0][inputs.input_ids.shape[1]:],
                skip_special_tokens=True
            )
            print(f"ðŸ¤–: {response}")

        # Track features
        active_features = []
        if self.soul._current_activations is not None:
            active = torch.nonzero(self.soul._current_activations > 5.0).squeeze(-1)
            if active.numel() > 0:
                active_features = active.tolist()[:10] if active.dim() > 0 else [active.item()]

        # Store memory
        affect = self.soul.last_affect
        adrenaline = min(1.0, affect.arousal + 0.2)
        resp_tokens = len(self.tokenizer.encode(response))
        
        self.memory.append(MemoryFragment(
            "assistant", response, current_time,
            adrenaline, affect.valence, affect.novelty,
            tokens=resp_tokens, active_features=active_features
        ))
        
        for m in self.memory:
            m.decay()
        
        del inputs
        clean_memory()
        
        if self.debug_mode:
            self._print_debug()

    def _print_debug(self):
        affect = self.soul.last_affect
        stats = self.soul.get_dimension_stats()
        
        print(f"\n  [DEBUG v9.0.2]")
        print(f"  P:{affect.pleasure:+.3f} N:{affect.pain:+.3f} Nov:{affect.novelty:.3f} â†’ V:{affect.valence:+.3f}")
        print(f"  Fatigue: {self.soul.fatigue:.1f} | LR: {self.soul.lr:.6f}")
        print(f"  Dims: P={stats['pleasure']} N={stats['pain']} Nov={stats['novelty']} ?={stats['unknown']}")
        
        if self.soul.debug_data["discovered"]:
            print(f"  âœ¨ {', '.join(self.soul.debug_data['discovered'])}")
        
        pos = [f"{self.soul.get_feature_name(i)}" for i, v in self.soul.debug_data["top_pos"] if v > 0]
        if pos:
            print(f"  [+] {', '.join(pos)}")
        
        neg = [f"{self.soul.get_feature_name(i)}" for i, v in self.soul.debug_data["top_neg"] if v < 0]
        if neg:
            print(f"  [-] {', '.join(neg)}")

    def trigger_dream(self):
        new_core, new_peripheral = self.soul.dream(
            self.core_identity,
            self.peripheral_identity,
            self.memory
        )
        
        if new_core and len(new_core) > 20:
            self.core_identity = new_core
        if new_peripheral:
            self.peripheral_identity = new_peripheral
        
        self._save_identity()

    def show_status(self):
        affect = self.soul.last_affect
        stats = self.soul.get_dimension_stats()
        
        print(f"\nâ•â•â• ANIMA STATUS â•â•â•")
        print(f"Identity Age: {self.soul.identity_age} dreams")
        print(f"Fatigue: {self.soul.fatigue:.1f} / {self.soul.sleep_threshold}")
        print(f"Learning Rate: {self.soul.lr:.6f}")
        print(f"\nAffect:")
        print(f"  Pleasure: {affect.pleasure:+.3f}")
        print(f"  Pain:     {affect.pain:+.3f}")
        print(f"  Novelty:  {affect.novelty:.3f}")
        print(f"  Valence:  {affect.valence:+.3f}")
        print(f"\nDimensions:")
        print(f"  Pleasure: {stats['pleasure']}")
        print(f"  Pain:     {stats['pain']}")
        print(f"  Novelty:  {stats['novelty']}")
        print(f"  Unknown:  {stats['unknown']}")
        print(f"  Learned:  {stats['total_learned']}")


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--stream", action="store_true")
    parser.add_argument("--cot", action="store_true")
    parser.add_argument("--model", default="meta-llama/Meta-Llama-3.1-8B-Instruct")
    parser.add_argument("--layer", type=int, default=20)
    parser.add_argument("--sae_release", default="llama_scope_lxr_8x")
    parser.add_argument("--sae_id", default=None)
    parser.add_argument("--context_limit", type=int, default=4096)
    parser.add_argument("--resonance_weight", type=float, default=0.5)
    args = parser.parse_args()

    args.model = os.path.expanduser(args.model)
    device = "mps" if torch.backends.mps.is_available() else "cuda"
    print(f"Anima 9.0.2 (Differential Hebbian) on {device}")

    clean_memory()

    model = AutoModelForCausalLM.from_pretrained(
        args.model, torch_dtype=torch.bfloat16, device_map=device
    )
    tokenizer = AutoTokenizer.from_pretrained(args.model)
    
    clean_memory()
    
    if args.sae_id is None:
        args.sae_id = f"l{args.layer}r_8x"
    
    sae = SAE.from_pretrained(args.sae_release, args.sae_id, device=device)
    
    soul = AnimaSoul(sae, model, tokenizer, layer=args.layer, 
                     resonance_weight=args.resonance_weight, device=device)
    runtime = AnimaRuntime(
        args.model, model, tokenizer, soul, args.context_limit,
        device, use_stream=args.stream, use_cot=args.cot
    )
    
    save_path = runtime.base_dir / "anima_soul.pt"
    if save_path.exists():
        soul.load_state(save_path)
    
    model.model.layers[args.layer].register_forward_hook(soul)
    
    print(f"\nâ•â•â• ANIMA 9.0.2: DIFFERENTIAL HEBBIAN â•â•â•")
    print(f"Model: {args.model}")
    print(f"Resonance Weight: {args.resonance_weight}")
    print(f"Identity: {runtime.core_identity[:60]}...")
    print("\nCommands: /status /debug /save /dream /quit")
    
    while True:
        try:
            if soul.fatigue > soul.sleep_threshold:
                print(f"\nðŸ¥± Fatigue threshold reached.")
                runtime.trigger_dream()
                print("âœ¨ Refreshed.")

            u = get_input("\nðŸ§‘: ").strip()
            if not u:
                continue
            
            if u == "/quit":
                break
            if u == "/status":
                runtime.show_status()
                continue
            if u == "/debug":
                runtime.debug_mode = not runtime.debug_mode
                print(f"Debug: {'ON' if runtime.debug_mode else 'OFF'}")
                continue
            if u == "/save":
                soul.save_state(save_path)
                continue
            if u == "/dream":
                runtime.trigger_dream()
                continue
            
            runtime.generate(u)
            
        except KeyboardInterrupt:
            break
    
    print("\n[Saving...]")
    soul.save_state(save_path)


if __name__ == "__main__":
    main()